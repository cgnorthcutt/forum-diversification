{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mmr' from 'mmr.pyc'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import mmr\n",
    "reload(mmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BigQuery code used to select the top 10 forum discussions\n",
    "# which have the highest sum of scores across all comments\n",
    "# in the forum discussion.\n",
    "\n",
    "# SELECT mongoid as thread_id_from_url, title, body as question\n",
    "# FROM [harvardx-data:HarvardX__HDS3221_2x__1T2016_latest.forum] A\n",
    "# JOIN \n",
    "# (\n",
    "#   SELECT\n",
    "#     thread_id_from_url, sum(score) as sum_score, nscored_comments\n",
    "#   FROM\n",
    "#     (\n",
    "#     SELECT \n",
    "#       comment_thread_id as thread_id_from_url, \n",
    "#       child_count as score, \n",
    "#       SUM(child_count > 0) OVER (PARTITION BY comment_thread_id) as nscored_comments,\n",
    "#       COUNT(*) OVER (PARTITION BY comment_thread_id) as ncomments\n",
    "#     FROM [harvardx-data:HarvardX__HDS3221_2x__1T2016_latest.forum]\n",
    "#     where parent_id IS NULL # Not a reply to a comment, just a comment.\n",
    "#     and comment_thread_id IS NOT NULL\n",
    "#   )\n",
    "#   WHERE nscored_comments >= 20\n",
    "#   #AND ncomments >= 20\n",
    "#   GROUP BY thread_id_from_url, nscored_comments\n",
    "# ) B\n",
    "# ON A.mongoid = B.thread_id_from_url\n",
    "# where _type = \"CommentThread\"\n",
    "# and not title contains \"Introduce Yourself\"\n",
    "# and not title contains \"Nondiscrimination/anti-harassment statement\"\n",
    "# and not title contains \"Farewell\"\n",
    "# and not title contains \"Help Thread\"\n",
    "# ORDER BY nscored_comments DESC\n",
    "\n",
    "# -- SELECT\n",
    "# --   *,\n",
    "# --   sum_body_length_per_topic / num_responses AS avg_response_length\n",
    "# -- FROM\n",
    "# -- (\n",
    "# --   SELECT \n",
    "# --     comment_thread_id as thread_id_from_url, \n",
    "# --     body, \n",
    "# --     child_count as num_replies, \n",
    "# --     LENGTH(body) as body_length,\n",
    "# --     SUM(LENGTH(body)) OVER (PARTITION BY comment_thread_id) as sum_body_length_per_topic,\n",
    "# --     COUNT(*) OVER (PARTITION BY comment_thread_id) as num_responses\n",
    "# --   FROM [harvardx-data:HarvardX__HDS3221_2x__1T2016_latest.forum]\n",
    "# --   #where comment_thread_id =\"5705e2fc10e0fd054b000bce\"\n",
    "# --   where parent_id IS NULL\n",
    "# --   and comment_thread_id IS NOT NULL\n",
    "# -- )\n",
    "# -- where num_responses >= 5\n",
    "# -- order by avg_response_length, thread_id_from_url, num_replies desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_comments(all_comments, all_scores, exclude_set, num_output): \n",
    "  # exclude_set: don't output a comment that we'll be comparing with\n",
    "  # set all_scores of exclude_set comments to 0 -> will make prob.\n",
    "  exclude_indices = [list(all_comments).index(cmt) for cmt in exclude_set]\n",
    "  \n",
    "  for idx in exclude_indices:\n",
    "    all_scores[idx] = 0\n",
    "  \n",
    "  probabilities = all_scores/float(sum(all_scores))\n",
    "  \n",
    "  comment_idxs = np.random.choice(len(all_comments), num_output, p=probabilities)\n",
    "  return [all_comments[cmt_idx] for cmt_idx in comment_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forum_topics = pd.read_csv(\"mmr_experiment_discussion_forum_topics.csv\").T.to_dict().values()\n",
    "df = pd.read_csv('../data/HarvardX__HDS_3221_2X__1T2016_scored_forum_responses_and_features.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = 5\n",
    "lambdas = [0.25, 0.75]\n",
    "ntrials = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "experiment_observed = []\n",
    "experiment_truth = []\n",
    "\n",
    "for i, topic_info in enumerate(forum_topics):\n",
    "  for lam in lambdas:\n",
    "    thread_id = df[\"thread_id_from_url\"]\n",
    "    topic_forum = df[df[\"thread_id_from_url\"] == topic_info[\"thread_id_from_url\"]]\n",
    "    all_comments = topic_forum.body.values\n",
    "    all_scores = MinMaxScaler().fit_transform(topic_forum.num_replies.values.reshape((len(topic_forum),1)))\n",
    "    all_scores = np.array([score[0] for score in all_scores])\n",
    "    \n",
    "    pairwise = mmr.tfidf_pca(all_comments)\n",
    "    \n",
    "    # Baseline uses lam = 1.0\n",
    "    comment_indices_baseline = mmr.mmr(pairwise, all_scores, K, lam=1.0)\n",
    "    baseline_ranking = all_comments[comment_indices_baseline]\n",
    "    \n",
    "    # Run mmr with PCA tfidf similarity matrix\n",
    "    comment_indices = mmr.mmr(pairwise, all_scores, K, lam)\n",
    "    mmr_ranking = all_comments[comment_indices]\n",
    "    \n",
    "    # Rankings are the same, nothing to compare for experiment.\n",
    "    # Remove and continue\n",
    "    if set(comment_indices_baseline) == set(comment_indices):\n",
    "      # if lam = 0.75 then 0.25 was added and needs to be removed\n",
    "      if lam == 0.75:\n",
    "        experiment_observed = experiment_observed[:-5]\n",
    "        experiment_truth = experiment_truth[:-5]\n",
    "      break\n",
    "    \n",
    "    both_rankings = [baseline_ranking, mmr_ranking]\n",
    "    # print(i, lam, comment_indices)\n",
    "    \n",
    "    exclude_set = set(list(baseline_ranking) + list(mmr_ranking))\n",
    "    test_comments = get_test_comments(all_comments, all_scores, exclude_set, ntrials)\n",
    "    \n",
    "    for test_comment in test_comments:\n",
    "      # Generate randomly a 0 or 1.\n",
    "      choice = np.random.randint(2)\n",
    "      \n",
    "      experiment_observed.append({\n",
    "          \"title\":topic_info[\"title\"],\n",
    "          \"question\":topic_info[\"question\"],\n",
    "          \"A\":both_rankings[choice],\n",
    "          \"B\":both_rankings[1 - choice],\n",
    "          \"C\":test_comment,\n",
    "        })\n",
    "      \n",
    "      experiment_truth.append({\n",
    "          \"A\": \"baseline\" if choice == 0 else \"mmr\",\n",
    "          \"B\": \"mmr\" if choice == 0 else \"baseline\",\n",
    "          \"mmr_lambda\": lam,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fetch first 100 trials for evaluation.\n",
    "experiment_truth = np.array(experiment_truth[:100])\n",
    "experiment_observed = np.array(experiment_observed[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(list(experiment_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for person in [\"curtis.txt\", \"carson.txt\", \"kim.txt\", \"naichun.txt\"]:\n",
    "  idx = range(100)\n",
    "  np.random.shuffle(idx)\n",
    "  pickle.dump(experiment_truth[idx], open(\"truth_\"+person+\".p\", 'wb'))\n",
    "  \n",
    "  f = open(person, 'wb')\n",
    "  for trial_num, exp_trial in enumerate(experiment_observed[idx]):\n",
    "    print(\"Trial\", trial_num, file=f)\n",
    "    print(file=f)\n",
    "    print(\"|------------|\", file=f)\n",
    "    print(\"| Question Q |\", file=f)\n",
    "    print(\"|------------|\", file=f)\n",
    "    print(repr(exp_trial[\"question\"]), file=f)\n",
    "    print(file=f)\n",
    "\n",
    "    for lst in [\"A\", \"B\"]:\n",
    "      print(\"|--------|\", file=f)\n",
    "      print(\"| List\", lst,\"|\", file=f)\n",
    "      print(\"|--------|\", file=f)\n",
    "      print(file=f)\n",
    "\n",
    "      for i, c in enumerate(exp_trial[lst]):\n",
    "        print(\"[\"+str(i+1)+\"]\", repr(c), file=f)\n",
    "        print(file=f)\n",
    "\n",
    "      print(file=f)\n",
    "\n",
    "    print(\"|-----------|\", file=f)\n",
    "    print(\"| Comment C |\", file=f)\n",
    "    print(\"|-----------|\", file=f)\n",
    "    print(repr(exp_trial[\"C\"]), file=f)\n",
    "    print(file=f)\n",
    "    print(file=f)\n",
    "    print(file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25    75\n",
       "0.75    25\n",
       "Name: mmr_lambda, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(pd.read_pickle(\"truth_curtis.txt.p\"))).mmr_lambda.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
