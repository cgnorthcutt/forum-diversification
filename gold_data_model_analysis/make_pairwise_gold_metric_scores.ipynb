{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pairwise_cosine_similarity_train, pairwise_cosine_similarity_test, gold_matrix_train, gold_data_train, gold_matrix_test, gold_data_test):\n",
    "  \n",
    "  # Scale / Normalize pairwise_cosine_similarity\n",
    "  pairwise_cosine_similarity_test = MinMaxScaler().fit_transform(pairwise_cosine_similarity_test)\n",
    "  \n",
    "  # Convert gold matrices to np.array (instead of pd.DataFrame) if necessary\n",
    "  gold_matrix_train = gold_matrix_train.values if isinstance(gold_matrix_train, pd.DataFrame) else gold_matrix_train\n",
    "  gold_matrix_test = gold_matrix_test.values if isinstance(gold_matrix_test, pd.DataFrame) else gold_matrix_test\n",
    "  \n",
    "  # Compute list of indices of sorted matrix values in list form\n",
    "  flat_cossim_train = pairwise_cosine_similarity_train.flatten()\n",
    "  flat_cossim_test = pairwise_cosine_similarity_test.flatten()\n",
    "  flat_gold_train = gold_matrix_train.flatten()\n",
    "  flat_gold_test = gold_matrix_test.flatten()\n",
    "  \n",
    "  npairs_train = float(len(flat_cossim_train))\n",
    "  npairs_test = float(len(flat_cossim_test))\n",
    "  \n",
    "  metrics = {}\n",
    "  \n",
    "#   #\n",
    "#   # Metric 0: avg_diff (Average difference of cossine similarity for gold score classes)\n",
    "#   #\n",
    "  \n",
    "#   # Compute avg consine similarity for same cluster comments and different cluster topics and subtract.\n",
    "#   same_cluster_avg_score = np.multiply(pairwise_cosine_similarity_test, gold_matrix_test).sum() / gold_matrix_test.sum()\n",
    "#   diff_cluster_avg_score = np.multiply(pairwise_cosine_similarity_test, 1-gold_matrix_test).sum() / (1-gold_matrix_test).sum()\n",
    "#   metrics[\"avg_diff\"] = same_cluster_avg_score - diff_cluster_avg_score\n",
    "#   print(\"Avg Difference score:\", same_cluster_avg_score, \"-\", diff_cluster_avg_score, \"=\", metrics[\"avg_diff\"])\n",
    "  \n",
    "#   #\n",
    "#   # Metric 1: median_diff (Median difference of cossine similarity for gold score classes)\n",
    "#   #\n",
    "  \n",
    "#   gold0_values = flat_cossim_test[flat_gold_test == 0]\n",
    "#   gold1_values = flat_cossim_test[flat_gold_test == 1]\n",
    "#   np.median(gold1_values) - np.median(gold0_values)\n",
    "#   metrics[\"median_diff\"] = np.median(gold1_values) - np.median(gold0_values)\n",
    "#   print(\"Median Difference score:\", np.median(gold1_values), \"-\", np.median(gold0_values), \"=\", metrics[\"median_diff\"])\n",
    "  \n",
    "  #\n",
    "  # Metric 2: median_quantile_diff (Median normalized rank difference of cossine similarity for gold score classes)\n",
    "  #\n",
    "  \n",
    "  ranks = rankdata(flat_cossim_test)\n",
    "  gold0_values_quantile = ranks[flat_gold_test == 0] / npairs_test\n",
    "  gold1_values_quantile = ranks[flat_gold_test == 1] / npairs_test\n",
    "  np.median(gold1_values_quantile) - np.median(gold0_values_quantile)\n",
    "  metrics[\"median_quantile_diff\"] = np.median(gold1_values_quantile) - np.median(gold0_values_quantile)\n",
    "  print(\"Median Quantile (Rank) Difference score:\", np.median(gold1_values_quantile), \"-\", np.median(gold0_values_quantile), \"=\", metrics[\"median_quantile_diff\"])\n",
    "  sys.stdout.flush()\n",
    "  \n",
    "  #\n",
    "  # Metric 3: logreg_acc_pairwise_binary Binary Logistic Regression Accuracy\n",
    "  # \n",
    "  \n",
    "  X_train = flat_cossim_train.reshape((int(npairs_train), 1))\n",
    "  y_train = flat_gold_train.reshape((int(npairs_train), ))\n",
    "  X_test = flat_cossim_test.reshape((int(npairs_test), 1))\n",
    "  y_test = flat_gold_test.reshape((int(npairs_test), ))\n",
    "  \n",
    "  clf = LogisticRegression()\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_pred = clf.predict(X_test)\n",
    "  acc = accuracy_score(y_true = y_test, y_pred = y_pred)\n",
    "  metrics[\"logreg_acc_pairwise_binary\"] = acc\n",
    "  print(\"Pairwise Binary Logistic Regression Accuracy score:\", acc)\n",
    "  print(\"\\nThe next test uses parameter optimization over a random forest\\nclassifier's parameters and may take 30s to 2 min to run.\\n\")\n",
    "  sys.stdout.flush()\n",
    "  \n",
    "  #\n",
    "  # Metric 4: random_forest_acc_pairwise_binary Binary Random Forest Accuracy\n",
    "  # \n",
    "  \n",
    "  clf = RandomForestClassifier(n_jobs=8)\n",
    "  # specify parameters and distributions to sample from\n",
    "  param_dist = {#\"n_estimators\": sp_randint(10, 20),\n",
    "                \"max_depth\": [3, None],\n",
    "                #\"max_features\": sp_randint(1, 11),\n",
    "                \"min_samples_split\": sp_randint(1, 11),\n",
    "                \"min_samples_leaf\": sp_randint(1, 11),\n",
    "                \"bootstrap\": [True, False],\n",
    "                \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "  # run randomized search, n_iter trials\n",
    "  best_clf = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=5)\n",
    "  best_clf.fit(X_train, y_train)\n",
    "  y_pred = best_clf.predict(X_test)\n",
    "  acc = accuracy_score(y_true = y_test, y_pred = y_pred)\n",
    "  metrics[\"random_forest_acc_pairwise_binary\"] = acc\n",
    "  print(\"Pairwise Binary Random Forest Accuracy score:\", acc)\n",
    "  sys.stdout.flush()\n",
    "  \n",
    "#   #\n",
    "#   # Metric 4: logreg_acc_topic Binary Logistic Regression Accuracy\n",
    "#   # \n",
    "  \n",
    "#   clf = LogisticRegression()\n",
    "#   clf.fit(flat_cossim_train, gold_data)\n",
    "#   y_pred = clf.pred(flat_cossim_test)\n",
    "#   acc = accuracy_score(y_true = flat_gold, y_pred = y_pred)\n",
    "#   metrics[\"logreg_acc_binary\"] = acc\n",
    "#   print(\"Binary Logistic Regression Accuracy score:\", acc)\n",
    "#   sys.stdout.flush()\n",
    "  \n",
    "  return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
