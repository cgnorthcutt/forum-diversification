{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import sys, gensim, re, csv, operator\n",
    "from __future__ import absolute_import\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from make_pairwise_gold_metric_scores import compute_metrics\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "# Load gold training and testing data\n",
    "gold_matrix_train = pd.read_csv('data/gold_matrix_train_HarvardX__HDS_3221_2X__1T2016.csv.gz', compression='gzip')\n",
    "df_gold_train = pd.read_csv('data/gold_data_train_HarvardX__HDS_3221_2X__1T2016.csv.gz', compression='gzip')\n",
    "gold_matrix_test = pd.read_csv('data/gold_matrix_test_HarvardX__HDS_3221_2X__1T2016.csv.gz', compression='gzip')\n",
    "df_gold_test = pd.read_csv('data/gold_data_test_HarvardX__HDS_3221_2X__1T2016.csv.gz', compression='gzip')\n",
    "train_resps = df_gold_train.body.values\n",
    "test_resps = df_gold_test.body.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfidfCorpus(corpus):\n",
    "  tfidf = models.TfidfModel(corpus)\n",
    "  corpus_tfidf = tfidf[corpus]\n",
    "  return corpus_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_doc(document):\n",
    "  # clean and tokenize document string\n",
    "  raw = document.lower().decode('utf-8').strip()\n",
    "  tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "  # remove stop words from tokens\n",
    "  stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "\n",
    "  # stem tokens\n",
    "  stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "\n",
    "  # return tokens for this company\n",
    "  return stopped_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readFile(response_array):\n",
    "  fileData = []\n",
    "  rawDocs = {}\n",
    "  doc_id = 1\n",
    "  \n",
    "  for resp in response_array:\n",
    "    rawDocs[doc_id] = resp.strip()\n",
    "    fileData.append(format_doc(resp))\n",
    "    doc_id += 1\n",
    "\n",
    "  return (fileData, rawDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCorpusData(response_array):\n",
    "  all_tokens, rawDocs = readFile(response_array)\n",
    "  \n",
    "  # turn our tokenized documents into a id <-> term dictionary\n",
    "  dictionary = corpora.Dictionary(all_tokens)\n",
    "  \n",
    "  # convert tokenized documents into a document-term matrix\n",
    "  corpus = [dictionary.doc2bow(text) for text in all_tokens]\n",
    "  \n",
    "  return (all_tokens, rawDocs, dictionary, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topicDistsOfCps(ldaModel, dictionary, rawCps):\n",
    "  cpTopicDist = {}\n",
    "    \n",
    "  for cp in rawCps:\n",
    "    vec_bow = dictionary.doc2bow(rawCps[cp].lower().split())\n",
    "    cpTopicDist[cp] = ldaModel[vec_bow]\n",
    "    \n",
    "  return cpTopicDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testGold(n_topics, n_iters, doc_array, gold_matrix):\n",
    "  all_tokens, rawDocs, dictionary, corpus = getCorpusData(doc_array)\n",
    "  tfidf_corpus = tfidfCorpus(corpus)\n",
    "\n",
    "  # generate LDA model with n_topics topics and n_iters iterations\n",
    "  ldaModel = gensim.models.ldamodel.LdaModel(tfidf_corpus, num_topics=n_topics, id2word = dictionary, passes=n_iters)\n",
    "  vis_data = pyLDAvis.gensim.prepare(ldaModel, tfidf_corpus, dictionary)\n",
    "\n",
    "  # \n",
    "  emd = topicDistsOfCps(ldaModel, dictionary, rawDocs)\n",
    "  \n",
    "  # cosine similarity matrix\n",
    "  M_cos = np.zeros((len(emd),len(emd)))\n",
    "\n",
    "  for key1,value1 in emd.items():\n",
    "      for key2,value2 in emd.items():\n",
    "          temp = gensim.matutils.cossim(value1, value2)\n",
    "          M_cos[key1-1][key2-1] = temp\n",
    "            \n",
    "  # largest similarity == 1\n",
    "  M_cos = MinMaxScaler().fit_transform(M_cos)          \n",
    "            \n",
    "  DF = pd.DataFrame(M_cos)\n",
    "  \n",
    "  tmp_matrix = np.copy(DF.values)\n",
    "  \n",
    "  same_mean = np.sum(tmp_matrix * gold_matrix.values) / np.count_nonzero(gold_matrix == 1) \n",
    "  diff_mean = np.sum(tmp_matrix * (1 - gold_matrix.values)) / np.count_nonzero(gold_matrix == 0) \n",
    "  \n",
    "  return (same_mean, diff_mean, DF, vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runs = {}\n",
    "topics = [10, 15, 30, 45, 50, 55, 60, 65, 80, 100, 125]\n",
    "iters = [50, 75, 90, 100, 125, 150, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for t in topics:\n",
    "  for i in iters:\n",
    "    runs[(t,i)] = testGold(t, i, train_resps, gold_matrix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runs_mean_diff = np.zeros((len(topics),len(iters)))\n",
    "for r in runs:\n",
    "  runs_mean_diff[topics.index(r[0])][iters.index(r[1])] = runs[r][0] - runs[r][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runs = pickle.load( open( \"runs.p\", \"rb\" ) )\n",
    "runs_mean_diff = pickle.load( open( \"runs_mean_diff.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50</th>\n",
       "      <th>75</th>\n",
       "      <th>90</th>\n",
       "      <th>100</th>\n",
       "      <th>125</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.008045</td>\n",
       "      <td>-0.007801</td>\n",
       "      <td>-0.008359</td>\n",
       "      <td>-0.006240</td>\n",
       "      <td>-0.004534</td>\n",
       "      <td>-0.004735</td>\n",
       "      <td>-0.005543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.003117</td>\n",
       "      <td>-0.005859</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.013692</td>\n",
       "      <td>-0.005190</td>\n",
       "      <td>-0.002129</td>\n",
       "      <td>-0.006842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.094061</td>\n",
       "      <td>0.062550</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>0.010064</td>\n",
       "      <td>0.051544</td>\n",
       "      <td>-0.002266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.036505</td>\n",
       "      <td>0.069579</td>\n",
       "      <td>0.040446</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.012925</td>\n",
       "      <td>0.059990</td>\n",
       "      <td>0.095055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.038476</td>\n",
       "      <td>-0.002682</td>\n",
       "      <td>0.004437</td>\n",
       "      <td>0.055167</td>\n",
       "      <td>0.055455</td>\n",
       "      <td>0.048772</td>\n",
       "      <td>0.051373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.057735</td>\n",
       "      <td>0.035021</td>\n",
       "      <td>0.063727</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>0.056552</td>\n",
       "      <td>0.019494</td>\n",
       "      <td>0.050926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.068379</td>\n",
       "      <td>0.010769</td>\n",
       "      <td>0.042650</td>\n",
       "      <td>0.005839</td>\n",
       "      <td>0.044423</td>\n",
       "      <td>0.044123</td>\n",
       "      <td>0.008494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.043081</td>\n",
       "      <td>0.098811</td>\n",
       "      <td>0.020660</td>\n",
       "      <td>0.024422</td>\n",
       "      <td>0.096965</td>\n",
       "      <td>0.023943</td>\n",
       "      <td>0.068797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.054470</td>\n",
       "      <td>0.050660</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.022111</td>\n",
       "      <td>0.040155</td>\n",
       "      <td>0.016039</td>\n",
       "      <td>0.083259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.024047</td>\n",
       "      <td>0.011970</td>\n",
       "      <td>0.038582</td>\n",
       "      <td>0.045799</td>\n",
       "      <td>0.067324</td>\n",
       "      <td>0.055855</td>\n",
       "      <td>0.027627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.044263</td>\n",
       "      <td>0.088315</td>\n",
       "      <td>0.054946</td>\n",
       "      <td>0.020856</td>\n",
       "      <td>0.028407</td>\n",
       "      <td>0.028749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          50        75        90        100       125       150       200\n",
       "10  -0.008045 -0.007801 -0.008359 -0.006240 -0.004534 -0.004735 -0.005543\n",
       "15  -0.003117 -0.005859  0.005464  0.013692 -0.005190 -0.002129 -0.006842\n",
       "30   0.000756  0.094061  0.062550  0.006097  0.010064  0.051544 -0.002266\n",
       "45   0.036505  0.069579  0.040446  0.001371  0.012925  0.059990  0.095055\n",
       "50   0.038476 -0.002682  0.004437  0.055167  0.055455  0.048772  0.051373\n",
       "55   0.057735  0.035021  0.063727  0.010029  0.056552  0.019494  0.050926\n",
       "60   0.068379  0.010769  0.042650  0.005839  0.044423  0.044123  0.008494\n",
       "65   0.043081  0.098811  0.020660  0.024422  0.096965  0.023943  0.068797\n",
       "80   0.054470  0.050660  0.020700  0.022111  0.040155  0.016039  0.083259\n",
       "100  0.024047  0.011970  0.038582  0.045799  0.067324  0.055855  0.027627\n",
       "125  0.006472  0.044263  0.088315  0.054946  0.020856  0.028407  0.028749"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# table of training data with various num of topics & iterations\n",
    "pd.DataFrame(runs_mean_diff, index=topics, columns=iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_same_mean, tst_diff_mean, tst_DF, tst_vis_data = testGold(65, 75, test_resps, gold_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Quantile (Rank) Difference score: 0.604327862469 - 0.475611999972 = 0.128715862498\n",
      "Pairwise Binary Logistic Regression Accuracy score: 0.815278216339\n",
      "\n",
      "The next test uses parameter optimization over a random forest\n",
      "classifier's parameters and may take 30s to 2 min to run.\n",
      "\n",
      "Pairwise Binary Random Forest Accuracy score: 0.816743075159\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logreg_acc_pairwise_binary</th>\n",
       "      <td>0.815278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_quantile_diff</th>\n",
       "      <td>0.128716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest_acc_pairwise_binary</th>\n",
       "      <td>0.816743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Score\n",
       "logreg_acc_pairwise_binary         0.815278\n",
       "median_quantile_diff               0.128716\n",
       "random_forest_acc_pairwise_binary  0.816743"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_2 = compute_metrics(runs[(65,75)][2].values, tst_DF.values, gold_matrix_train, df_gold_train, gold_matrix_test, df_gold_test)\n",
    "pretty_metrics_2 = pd.DataFrame(pd.Series(metrics_2), columns = [\"Score\"])\n",
    "pretty_metrics_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
